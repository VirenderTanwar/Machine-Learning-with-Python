{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Consumer Disputing on the resolution provided by Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_train=pd.read_csv(r'/content/Consumer_Complaints_train.csv')\n",
    "cc_test=pd.read_csv(r'/content/Consumer_Complaints_test_share.csv')\n",
    "cc_train['data']='train'\n",
    "cc_test['data']='test'\n",
    "cc_test['Consumer disputed?']=np.nan\n",
    "cc_all=pd.concat([cc_train,cc_test],0,sort=False)\n",
    "print(cc_train.isnull().sum())\n",
    "col_name=['Date received','Date sent to company']\n",
    "\n",
    "for i in col_name:\n",
    "    cc_all[i]=pd.to_datetime(cc_all[i])\n",
    "\n",
    "cc_all['Consumer disputed?']=(cc_all['Consumer disputed?']=='Yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_all.drop(['ZIP code','Complaint ID'],1,inplace=True)\n",
    "cc_all['Date Diff']=(pd.to_datetime(cc_all['Date sent to company'])-pd.to_datetime(cc_all['Date received']))/np.timedelta64(1,'D')\n",
    "def conversion(data,name):\n",
    "    m=name+'_Month'\n",
    "    d=name+'_Day'\n",
    "    data[m]=data[name].dt.month\n",
    "    data[d]=data[name].dt.day\n",
    "    data[m+'_sin']=np.sin(2*np.pi*(data[m]/max(data[m])))\n",
    "    data[m+'_cos']=np.cos(2*np.pi*(data[m]/max(data[m])))\n",
    "    data[d+'_sin']=np.sin(2*np.pi*(data[d]/max(data[d])))\n",
    "    data[d+'_cos']=np.cos(2*np.pi*(data[d]/max(data[d])))\n",
    "    data=data.drop([m,d,name],1,inplace=True)\n",
    "    return data\n",
    "\n",
    "conversion(cc_all,'Date received')\n",
    "conversion(cc_all,'Date sent to company')\n",
    "\n",
    "for i in cc_all.select_dtypes(['object']).columns:\n",
    "    cc_all[i]=np.where(cc_all[i].isnull(),'missing',cc_all[i])\n",
    "    \n",
    "    [(i,cc_all[i].isnull().sum()) for i in cc_all.columns]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(data,col,n):\n",
    "    freq=data[col].value_counts()\n",
    "    k=freq.index[freq>n][:-1]\n",
    "    for cat in k:\n",
    "        name=col+\"_\"+str(cat)\n",
    "        data[name]=(data[col]==cat).astype(int)\n",
    "    del data[col]\n",
    "    \n",
    "dummies(cc_all,'Product',0)\n",
    "dummies(cc_all,'Sub-product',5000)\n",
    "dummies(cc_all,'Issue',5000)\n",
    "dummies(cc_all,'Sub-issue',5000)\n",
    "dummies(cc_all,'Company public response',5000)\n",
    "dummies(cc_all,'Company',5000)\n",
    "dummies(cc_all,'State',5000)\n",
    "dummies(cc_all,'Tags',5000)\n",
    "dummies(cc_all,'Consumer consent provided?',5000)\n",
    "dummies(cc_all,'Timely response?',5000)\n",
    "dummies(cc_all,'Submitted via',5000)\n",
    "dummies(cc_all,'Company response to consumer',5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemma=WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message=message.lower()\n",
    "    for i in punctuation:\n",
    "        message=message.replace(i,\"\")\n",
    "    message=message.replace('x',\"\")\n",
    "    words=word_tokenize(message)\n",
    "    words_sans_stop=[]\n",
    "    for word in words:\n",
    "        if word in my_stop:continue\n",
    "        if word.isdigit()==True:continue\n",
    "        words_sans_stop.append(word)\n",
    "    return [lemma.lemmatize(word) for word in words_sans_stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(analyzer=split_into_lemmas,min_df=0.01,max_df=0.8,max_features=400,stop_words=my_stop)\n",
    "tfidf.fit(cc_all['Consumer complaint narrative'])\n",
    "ccn_data=tfidf.transform(cc_all['Consumer complaint narrative'].values.astype('U'))\n",
    "ccn_data=pd.DataFrame(ccn_data.toarray(),columns=tfidf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(result,n_top):\n",
    "    for i in range(0,n_top+1):\n",
    "        candidates=np.flatnonzero(result['rank_test_score']==i)\n",
    "        for candidate in candidates:\n",
    "            print('Model wiht Rank ',i)\n",
    "            print(\"Mean Valdiation Score & Std Score\",result['mean_test_score'][candidate],\n",
    "                 result['std_test_score'][candidate])\n",
    "            print(\"Parameter\",result['params'][candidate])\n",
    "            print(\"^_^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cc_all['Consumer complaint narrative']\n",
    "cc_all.reset_index(drop=True,inplace=True)\n",
    "ccn_data.reset_index(drop=True,inplace=True)\n",
    "cc=pd.concat([cc_all,ccn_data],1)\n",
    "train=cc.loc[cc_all['data']=='train',]\n",
    "del train['data']\n",
    "test=cc.loc[cc_all['data']=='test',]\n",
    "test=test.drop(['Consumer disputed?','data'],1)\n",
    "model_train,val=train_test_split(train,test_size=0.4,random_state=2)\n",
    "x_train=model_train.drop(['Consumer disputed?'],1)\n",
    "y_train=model_train['Consumer disputed?']\n",
    "x_val=val.drop(['Consumer disputed?'],1)\n",
    "y_val=val['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_param={'penalty':['l1','l2'],'C':[0.01,0.1,0.5,0.15,0.2],'class_weight':['balanced']}\n",
    "clf=LogisticRegression()\n",
    "\n",
    "log_grid=GridSearchCV(clf,cv=15,param_grid=log_param,scoring='roc_auc',n_jobs=-1,verbose=20)\n",
    "log_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(log_grid.cv_results_,5)\n",
    "log_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val,log.predict_proba(x_val)[:,1])\n",
    "roc_auc_score(y_train,log.predict_proba(x_train)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score=log.predict_proba(test)[:,1]\n",
    "cc_test['Consumer disputed?']=test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
