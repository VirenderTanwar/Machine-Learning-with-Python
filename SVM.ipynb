{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\212448576\\Downloads\\Reuters_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_crude_10011.txt',\n",
       " 'training_crude_10078.txt',\n",
       " 'training_crude_10080.txt',\n",
       " 'training_crude_10106.txt',\n",
       " 'training_crude_10168.txt',\n",
       " 'training_crude_10190.txt',\n",
       " 'training_crude_10192.txt',\n",
       " 'training_crude_10200.txt',\n",
       " 'training_crude_10228.txt',\n",
       " 'training_crude_1026.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=[x for x in files if '.txt' in x]\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "article_text=[]\n",
    "\n",
    "for file in files:\n",
    "    if '.txt' not in file:continue\n",
    "    f=open(path+'\\\\'+file,encoding='latin-1')\n",
    "    article_text.append(\" \".join([line.strip() for line in f if line.strip()!=\"\"]))\n",
    "    \n",
    "    if \"crude\" in file:\n",
    "        target.append(\"crude\")\n",
    "    else:\n",
    "        target.append(\"money\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=pd.DataFrame({'target':target,'article_text':article_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crude</td>\n",
       "      <td>CANADA OIL EXPORTS RISE 20 PCT IN 1986 Canadia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crude</td>\n",
       "      <td>BP &amp;lt;BP&gt; DOES NOT PLAN TO HIKE STANDARD &amp;lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crude</td>\n",
       "      <td>BP&amp;lt;BP&gt; OFFER RAISES EXPECTATIONS FOR OIL VA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crude</td>\n",
       "      <td>USX &amp;lt;X&gt; SAYS TALKS ENDED WITH BRITISH PETRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crude</td>\n",
       "      <td>BP &amp;lt;BP&gt; MAY HAVE TO RAISE BID -  ANALYSTS B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                       article_text\n",
       "0  crude  CANADA OIL EXPORTS RISE 20 PCT IN 1986 Canadia...\n",
       "1  crude  BP &lt;BP> DOES NOT PLAN TO HIKE STANDARD &lt;...\n",
       "2  crude  BP&lt;BP> OFFER RAISES EXPECTATIONS FOR OIL VA...\n",
       "3  crude  USX &lt;X> SAYS TALKS ENDED WITH BRITISH PETRO...\n",
       "4  crude  BP &lt;BP> MAY HAVE TO RAISE BID -  ANALYSTS B..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_train,article_test=train_test_split(mydata,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>crude</td>\n",
       "      <td>MALAYSIA TO CUT OIL OUTPUT FURTHER, TRADERS SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>money</td>\n",
       "      <td>BANKERS OPPOSE STRICT TAIWAN CURRENCY CONTROLS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>crude</td>\n",
       "      <td>OPEC WITHIN OUTPUT CEILING, SUBROTO SAYS Opec ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>money</td>\n",
       "      <td>U.K. MONEY MARKET SHORTAGE FORECAST AT 300 MLN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>money</td>\n",
       "      <td>CURRENCY FUTURES TO KEY OFF G-5, G-7 MEETINGS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                       article_text\n",
       "280  crude  MALAYSIA TO CUT OIL OUTPUT FURTHER, TRADERS SA...\n",
       "688  money  BANKERS OPPOSE STRICT TAIWAN CURRENCY CONTROLS...\n",
       "375  crude  OPEC WITHIN OUTPUT CEILING, SUBROTO SAYS Opec ...\n",
       "665  money  U.K. MONEY MARKET SHORTAGE FORECAST AT 300 MLN...\n",
       "589  money  CURRENCY FUTURES TO KEY OFF G-5, G-7 MEETINGS ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_train.reset_index(inplace=True,drop=True)\n",
    "article_test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=(article_train['target']=='money').astype(int)\n",
    "y_test=(article_test['target']=='money').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords\n",
    "# from string import punctuation\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# lemma=WordNetLemmatizer()\n",
    "# my_stop=set(stopwords.words('english')+list(punctuation))\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize # used to break sentences into words\n",
    "lemma = WordNetLemmatizer()\n",
    "my_stop=set(stopwords.words('english')+list(punctuation)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message=message.lower()\n",
    "    words=word_tokenize(message)\n",
    "    word_sans_stop=[]\n",
    "    for word in words:\n",
    "        if word in my_stop:continue\n",
    "        word_sans_stop.append(word)\n",
    "    return [lemma.lemmatize(word) for word in word_sans_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=CountVectorizer(analyzer=split_into_lemmas,min_df=20,max_df=500,stop_words=my_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(analyzer=split_into_lemmas,min_df=20,max_df=500,stop_words=my_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function split_into_lemmas at 0x102C5A08>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=500,\n",
       "        max_features=None, min_df=20, ngram_range=(1, 1),\n",
       "        preprocessor=None,\n",
       "        stop_words={'aren', 'she', 'is', 'doing', \"isn't\", 'out', \"she's\", \"shan't\", 'yourselves', \"mightn't\", 'were', 'other', \"needn't\", 'my', '`', 'his', 'these', 'yourself', 'them', 'once', 'under', 'or', 'themselves', 'yours', 'until', 'few', 'me', 'there', 'too', \"you'd\", \"it's\", 'a', 'more', 'above',... 'some', \"'\", 'do', 'again', 'hers', 'only', '#', \"weren't\", '(', 'have', \"mustn't\", 'ma', 'myself'},\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(article_train['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function split_into_lemmas at 0x102C5A08>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=500,\n",
       "        max_features=None, min_df=20, ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=None, smooth_idf=True,\n",
       "        stop_words={'aren', 'she', 'is', 'doing', \"isn't\", 'out', \"she's\", \"shan't\", 'yourselves', \"mightn't\", 'were', 'other', \"needn't\", 'my', '`', 'his', 'these', 'yourself', 'them', 'once', 'under', 'or', 'themselves', 'yours', 'until', 'few', 'me', 'there', 'too', \"you'd\", \"it's\", 'a', 'more', 'above',... 'some', \"'\", 'do', 'again', 'hers', 'only', '#', \"weren't\", '(', 'have', \"mustn't\", 'ma', 'myself'},\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(article_train['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf=tf.transform(article_train['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf=tfidf.transform(article_train['article_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<741x677 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 36338 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(741, 677)\n",
      "<class 'tuple'>\n",
      "[[0.         0.16087484 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.077667   0.06273514 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.06791456 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.08040204 0.         ... 0.         0.         0.        ]\n",
      " [0.02693875 0.13055784 0.         ... 0.         0.06033226 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_tf.shape)\n",
    "print(type(train_tf.shape))\n",
    "print(train_tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>''</th>\n",
       "      <th>'s</th>\n",
       "      <th>--</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>1.5</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>15</th>\n",
       "      <th>15.8</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123951</td>\n",
       "      <td>0.045114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077667</td>\n",
       "      <td>0.062735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.136024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139676</td>\n",
       "      <td>0.016117</td>\n",
       "      <td>0.076097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ''        's        --  ...         1  1.5       10       100   15  \\\n",
       "0  0.000000  0.160875  0.000000  0.0  0.090905  0.0  0.12917  0.000000  0.0   \n",
       "1  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.0   \n",
       "2  0.077667  0.062735  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.0   \n",
       "3  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.00000  0.136024  0.0   \n",
       "4  0.139676  0.016117  0.076097  0.0  0.000000  0.0  0.00000  0.000000  0.0   \n",
       "\n",
       "       15.8  ...   work  working  world  worth     would      year       yen  \\\n",
       "0  0.000000  ...    0.0      0.0    0.0    0.0  0.123951  0.045114  0.000000   \n",
       "1  0.000000  ...    0.0      0.0    0.0    0.0  0.069069  0.000000  0.000000   \n",
       "2  0.177247  ...    0.0      0.0    0.0    0.0  0.120840  0.000000  0.000000   \n",
       "3  0.000000  ...    0.0      0.0    0.0    0.0  0.188994  0.000000  0.000000   \n",
       "4  0.000000  ...    0.0      0.0    0.0    0.0  0.103485  0.000000  0.203471   \n",
       "\n",
       "   yesterday  yet  york  \n",
       "0        0.0  0.0   0.0  \n",
       "1        0.0  0.0   0.0  \n",
       "2        0.0  0.0   0.0  \n",
       "3        0.0  0.0   0.0  \n",
       "4        0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 677 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf=pd.DataFrame(train_tf.toarray(),columns=tf.get_feature_names())\n",
    "x_train_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['''', ''s', '--', '...', '1', '1.5', '10', '100', '15', '15.8',\n",
       "       ...\n",
       "       'work', 'working', 'world', 'worth', 'would', 'year', 'yen',\n",
       "       'yesterday', 'yet', 'york'],\n",
       "      dtype='object', length=677)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03963967, 0.01600937, 0.        , ..., 0.        , 0.04438868,\n",
       "        0.        ],\n",
       "       [0.        , 0.0476639 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.10564493, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.04776287, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07598587, 0.02045907, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf=tfidf.transform(article_test['article_text'])\n",
    "test_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>''</th>\n",
       "      <th>'s</th>\n",
       "      <th>--</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>1.5</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>15</th>\n",
       "      <th>15.8</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039640</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032136</td>\n",
       "      <td>0.044389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ''        's   --  ...    1  1.5        10       100   15  15.8  \\\n",
       "0  0.039640  0.016009  0.0  0.0  0.0  0.0  0.032136  0.044389  0.0   0.0   \n",
       "1  0.000000  0.047664  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   0.0   \n",
       "2  0.105645  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   0.0   \n",
       "\n",
       "   ...   work  working     world  worth     would  year  yen  yesterday  \\\n",
       "0  ...    0.0      0.0  0.000000    0.0  0.041116   0.0  0.0        0.0   \n",
       "1  ...    0.0      0.0  0.000000    0.0  0.000000   0.0  0.0        0.0   \n",
       "2  ...    0.0      0.0  0.085969    0.0  0.054790   0.0  0.0        0.0   \n",
       "\n",
       "        yet  york  \n",
       "0  0.044389   0.0  \n",
       "1  0.000000   0.0  \n",
       "2  0.000000   0.0  \n",
       "\n",
       "[3 rows x 677 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tf=pd.DataFrame(test_tf.toarray(),columns=tf.get_feature_names())\n",
    "x_test_tf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=knn.predict(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9623655913978495"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm=SVC(C=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=200, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(x_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946018893387314"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,clf_svm.predict(x_train_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989247311827957"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,clf_svm.predict(x_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(x_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989247311827957"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,clf_nb.predict(x_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
